---
title: ""
author: ""
date: ""
output: html_document
bibliography: analysis_citations.bib
---

### Introduction

This article presents a sample data analysis using methods described in two separate articles/tutorial papers [@masaki2010] [@distefano2009understanding]. The aims are:

1. Questionnaire validation
    - Explore the **empirical correlations** between our items; not just theorectical correlations (some questionnaire items might end up capturing none or more than one trait and we can't perform hypothesis testing with that item)
    - It allows us to trim away some items or construct new factors (traits) to explain our data
    - Sometime there are traits that are not measured at all properly by all our survey questions (and we have to add some).
2. Optimal scaling 
    - a composite measure of a particular domain can be calculated and used for subsequent analyses

**Our general workflow**:

1. PCA screening
2. EFA (Parallel Analysis, Screening, Factor Analysis)
3. Regression modeling

### Methods

An **artificial dataset** containing 500 observations of 15 questions was generated to simulate a 15 question-long survey form conducted on (n=500) respondents. They are designed as if asking about two different themes on a 7 point Likert-type scale.

Knowledge:

- Q1-3 are highly correlated (*r<sub>pc</sub>* > 0.70)
- Q3-6 are moderately correlated (0.50 < *r<sub>pc</sub>* < 0.60)

Behaviour:

- Q10-12 are highly correlated (*r<sub>pc</sub>* > 0.70)
- Q13-15 are moderately correlated (0.50 < *r<sub>pc</sub>* < 0.60)

Noise:

- Q7-9 are pure noise (*r<sub>pc</sub>* < 0.10) 

Note: *r<sub>pc</sub>* stands for Polychoric correlation coefficient [@ekstrom2011]

The questions were designed on the premise that:

1. The first 3 questions in each group are high quality and correlate highly with each other
2. The next 3 questions in each group are lower quality and only moderately correlated with each other
3. Q7-9 are pure noise and represent very poorly designed variables

```{r, echo=FALSE, message=FALSE, warning=FALSE}
mod.cor <- function(x1,r=0.6, n=500) {                    # length of vector
        rho   <- r                   # desired correlation = cos(angle)
        theta <- acos(rho)             # corresponding angle      # fixed given data
        x2    <- rnorm(n, 2, 0.5)      # new random data
        X     <- cbind(x1, x2)         # matrix
        Xctr  <- scale(X, center=TRUE, scale=FALSE)   # centered columns (mean 0)

        Id   <- diag(n)                               # identity matrix
        Q    <- qr.Q(qr(Xctr[ , 1, drop=FALSE]))      # QR-decomposition, just matrix Q
        P    <- tcrossprod(Q)          # = Q Q'       # projection onto space defined by x1
        x2o  <- (Id-P) %*% Xctr[ , 2]                 # x2ctr made orthogonal to x1ctr
        Xc2  <- cbind(Xctr[ , 1], x2o)                # bind to matrix
        Y    <- Xc2 %*% diag(1/sqrt(colSums(Xc2^2)))  # scale columns to length 1

        x3 <- Y[ , 2] + (1 / tan(theta)) * Y[ , 1]     # final new vector
        x3 <- x3 * 10 * 2
        return(round(x3,digits=0))
}
```

**Responses were coded (Strongly Disagree = -3 to Strongly Agree = 3)**
    
```{r,message=FALSE,warning=FALSE,echo=FALSE}
gen.data <- function(seed) { #Create fake data
        set.seed(seed)
        x <- sample(1:3, 500, replace=TRUE)
        x2 <- x - sample(1:2, 500, replace=TRUE)
        x3 <- x - sample(1:2, 500, replace=TRUE)
        x4 <- mod.cor(x,r=0.5)
        x5 <- mod.cor(x,r=0.49)
        x6 <- mod.cor(x,r=0.48)

        z <- sample(-3:3, 500, replace=TRUE) ####Noise
        z2 <- sample(-3:3, 500, replace=TRUE)
        z3 <- sample(-3:3, 500, replace=TRUE)
        
        y <- sample(-3:-1, 500, replace=TRUE) 
        y2 <- y + sample(1:2, 500, replace=TRUE)
        y3 <- y + sample(1:2, 500, replace=TRUE)
        y4 <- mod.cor(y, r=0.50)
        y5 <- mod.cor(y, r=0.51)
        y6 <- mod.cor(y, r=0.53)
        
        q <- -3:3
        data <- as.data.frame(list(Q1=factor(x,levels=levels(factor(q))),
                                Q2=factor(x2,levels=levels(factor(q))),
                                Q3=factor(x3,levels=levels(factor(q))),
                                Q4=factor(x4,levels=levels(factor(q))),
                                Q5=factor(x5,levels=levels(factor(q))),
                                Q6=factor(x6,levels=levels(factor(q))),
                                Q7=factor(z,levels=levels(factor(q))),
                                Q8=factor(z2,levels=levels(factor(q))),
                                Q9=factor(z3,levels=levels(factor(q))),
                                Q10=factor(y,levels=levels(factor(q))),
                                Q11=factor(y2,levels=levels(factor(q))),
                                Q12=factor(y3,levels=levels(factor(q))),
                                Q13=factor(y4,levels=levels(factor(q))),
                                Q14=factor(y5,levels=levels(factor(q))),
                                Q15=factor(y6,levels=levels(factor(q)))))
        data                   
}
data <- gen.data(1)
head(data)
```

```{r, echo=FALSE,message=FALSE,warning=FALSE}
balancer <- function(data) {
    balance <- data.frame(matrix(c(-3:3),nrow=7,ncol=15))
    names(balance) <- names(data)
    data <- rbind(data,balance)
    data <- data[sample(nrow(data),replace=F),]    
    data
}
```

All analyses were performed using R: A language and environment for statistical computing [@r2014]. Polychoric correlation matrices were calcuated using the "polycor" package [@polycor2010]. Functions from the "psych" packages were used for factor analysis [@psych2014]. Parallel analysis was performed with [@fabio2014].

```{r, echo=FALSE,message=FALSE,warning=FALSE}
library(psych)
library(polycor)
library(random.polychor.pa)
library("GPArotation")
```

### Results and Discussion

#### Step 1a. Generate items

Although artificial data was used in our analysis, the first step in the entire process is actually creating the survey instrument to measure the traits in our theoretical framework.

- Create items (i.e. Questions) that supposedly tap into the target construct
- Questions should be as expansive as possible: maximize face value
- Redundancy at this stage is fine but missing items is serious

#### Step 1b Screening items

The data set (n=500) was partioned into a training set (n=200) and test set (n=300) via simple random sampling to reduce bias. The training set was used for for item screening via PCA.

```{r, echo=TRUE}
index <- sample(nrow(data), 200)
train <- data[index, ]
test <- data[-index,]
test.original <- test
```

```{r,echo=FALSE,message=FALSE,warning=FALSE}
train <- balancer(train)
test <- balancer(test)
```

Non-linear principal components analysis with promax rotation was performed:

- We look for variables that load clearly onto one component
- Try to minimize cross-loading: i.e. high loadings on >1 component
- A cut-off that is generally accepted (but should be reported)
1. More than 0.50-0.60 on main factor and <0.20-0.30 on others
2. We can discard questions that don't meet this criteria
- *Make sure that the results make theorectical sense!*

```{r,echo=FALSE, warning=FALSE, message=FALSE,cache=TRUE}
train.cor <- hetcor(train,ML=F,std.err=F)
#### Run PCA
pca <- principal(train.cor$correlations, nfactors=10, rotate="promax")
pca
```

Q5 (0.83 on PC2 and -0.31 on PC7) can be discarded based on this criteria.

***

```{r, echo=FALSE}
test <- test[,-5] #remove Q5 and Q15 on test data set
```


#### Step 2. Exploratory Factor Analysis using the test set (n=300)

1. Determine number of factors underlying the data
2. Identify which variables load on to which factors
3. Remove variables which do not load onto any factors

*New data should be used*, the remaining observations i.e. the test set (n=300) will be used or the next part.

#### EFA: Parallel analysis

1. 500-1000 artificial datasets are generated with the same number of variables and same number of observations 
    - Note: 10 were used in this sample analysis to save time; the 10 simulations took 1 minute (500 will take ~1 hr and 1000 will take ~2hrs)
2. Variables in these datasets are random variables
3. Factor analysis is performed on each of these datasets and the eigenvalues of each factor generated are extracted
3. Repeating this many times will allow us to calculate the mean eigenvalue of a factor from datasets similar to what we have
4. An eigenvalue less than the mean would mean that a particular factor extracted is no more substantial (explains less) than a random factor (which really has no meaning); those factors are rejected 

```{r, echo=TRUE,message=TRUE,warnings=FALSE,cache=TRUE}
random.polychor.pa(nrep=10, data.matrix=data.matrix(test), q.eigen = 0.95, r.seed = 1, diff.fact=TRUE, distr="NULL", comparison = "random", fit.pa=FALSE, print.all=FALSE)
#Set significance of factors at 95th quantile
```

**Parallel analysis suggests that 2 factors are to be extracted**. Factor analysis was performed with the number of factors selected by Parallel Analysis.

#### EFA: Screening items

```{r, echo=TRUE, message=FALSE, warning=FALSE,cache=TRUE}
test.cor <- hetcor(test, ML=F, std.err=F)
test.fa <- fa(r=test.cor$correlations,nfactors=2,rotate="promax")
test.fa
#
```

This step is identical to that performed during PCA

- We look for factors that load clearly onto one component
- Try to minimize cross-loading: i.e. high loadings on >1 component
- A cut-off that is generally accepted (but should be reported)
1. More than 0.50-0.60 on main factor and <0.20-0.30 on others
2. We can discard questions that don't meet this criteria
- *Make sure that the results make theorectical sense!*

```{r, echo=FALSE,message=FALSE,warning=FALSE,cache=TRUE}
test.final <- test.original[,-c(5,7:9)]
test.final.cor <- hetcor(test.final, ML=F, std.err=F)
test.final.fa <- fa(r=test.final.cor$correlations,nfactors=2,rotate="promax")
test.final.fa
#
```

From the factor analysis above: 

- The "good questions" (Q1-3, Q10-12) load highly (>0.80) onto Factors 1 and 2 respectively
- The noise variables (Q7,Q8,Q9) don't load on either of the factors and can be discarded
- The remaining questions (Q4,6,13-15) were designed not be highly correlated with the the two factors but nonetheless did not meet the criteria to be discarded

#### Step 3. Creating factor scores

- Methods to create factor scores can be divided into non-refined and refined.
- The latter combines PCA and factor extraction methods to creating scores that may be, depending on the method chosen:
    - Highly correlated with a given factor
    - Obtain unbiased estimates of a true factor score
    - Preserves relationships between factors
- Three main methods exist to compute refined factor scores:
    1. Regression Scores - **chosen for demonstration**
    2. Bartlett Scores
    3. Anderson-Rubin Scores - it has been noted that above two have certain issues with subsequent regression analysis [@skrondal2001regression].

#### Step 4. Determining the validity of the factor scores computed (not performed)

- [@grice2001computing] suggests researchers examine the degree of indeterminacy in their factor solutions using three different measures:
1. validity – evidence of correlational relationships between factor scores and factor(s)
2. univocality- the extent to which factor scores are adequately or insufficiently correlated with other factors in the same analysis
3. correlational accuracy – which reports the extent to which correlations among the estimated factor scores match the correlations among the factors themselves. 

```{r, echo=TRUE}
scores <- factor.scores(data.matrix(test.final),f=test.final.fa,method="regression")$scores
test.wscores <- cbind(test.final,scores)
```

#### Step 5. Using the factor scores for regression

- Factors are new variables
- They must be checked for assumptions (e.g. normality) before conducting hypothesis testing
- Regression modeling can be performed with factors as predictors/outcomes

```{r,echo=FALSE,message=FALSE,warning=FALSE}
names(test.wscores)[names(test.wscores)=="MR1"] <- "Factor1"
names(test.wscores)[names(test.wscores)=="MR2"] <- "Factor2"
par(mfrow=c(1,2))
hist(test.wscores$Factor1, main="Knowledge", xlab="Factor Score", breaks=10)
hist(test.wscores$Factor2, main="Behaviour", xlab="Factor Score", breaks=10)
#
```

Fitting a linear regression model with the formula: 
<p>Practices = B<sub>0</sub> + B<sub>1</sub> *  Behavior

> H<sub>0</sub>: Β<sub>1</sub> = 0<br>
> H<sub>a</sub>: Β<sub>1</sub> ≠ 0

```{r, echo=FALSE,message=FALSE,warning=FALSE}
library(ggplot2)
qplot(Factor1, Factor2, data=test.wscores, geom=c("point","smooth"),method="lm",main="Scatterplot of Knowledge score and Behavior score", xlab="Knowledge", ylab="Behavior") + theme_bw()
summary(lm(Factor2 ~ Factor1, data=test.wscores)) 
```

**We fail to reject H<sub>0</sub> with p = 0.158**

### References
